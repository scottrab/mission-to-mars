{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting splinter\n",
      "  Using cached splinter-0.14.0-py3-none-any.whl (36 kB)\n",
      "Collecting selenium>=3.141.0\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: six in c:\\users\\asosn\\appdata\\roaming\\python\\python37\\site-packages (from splinter) (1.15.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from selenium>=3.141.0->splinter) (1.25.9)\n",
      "Installing collected packages: selenium, splinter\n",
      "Successfully installed selenium-3.141.0 splinter-0.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_managerNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached webdriver_manager-3.2.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting configparser\n",
      "  Using cached configparser-5.0.1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from webdriver_manager) (2.24.0)\n",
      "Collecting crayons\n",
      "  Using cached crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests->webdriver_manager) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests->webdriver_manager) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests->webdriver_manager) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asosn\\appdata\\roaming\\python\\python37\\site-packages (from crayons->webdriver_manager) (0.4.3)\n",
      "Installing collected packages: configparser, crayons, webdriver-manager\n",
      "Successfully installed configparser-5.0.1 crayons-0.4.0 webdriver-manager-3.2.2\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4Note: you may need to restart the kernel to use updated packages.\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from bs4) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asosn\\anaconda3\\envs\\pythondata\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1279 sha256=82108c0d9f555d292dc024c11926bb720782a86d8c812bd66ff3fb4e1c047310\n",
      "  Stored in directory: c:\\users\\asosn\\appdata\\local\\pip\\cache\\wheels\\0a\\9e\\ba\\20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - There is no [win32] chromedriver for browser 87.0.4280 in cache\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/87.0.4280.20/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\asosn\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.20]\n"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "# Setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Quotes to Scrape site\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top Ten tags'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the Title\n",
    "title = html_soup.find('h2').text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "inspirational\n",
      "life\n",
      "humor\n",
      "books\n",
      "reading\n",
      "friendship\n",
      "friends\n",
      "truth\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "# Scrape the top ten tags\n",
    "tag_box = html_soup.find('div', class_='tags-box')\n",
    "# tag_box\n",
    "tags = tag_box.find_all('a', class_='tag')\n",
    "\n",
    "for tag in tags:\n",
    "    word = tag.text\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1, 6):\n",
    "   html = browser.html\n",
    "   quote_soup = soup (html, 'html.parser')\n",
    "   quotes = quote_soup.find_all('div', class_='text')\n",
    "   for quote in quotes:\n",
    "      print('page:', x, '----------')\n",
    "      print(quote.text)\n",
    "   browser.links.find_by_partial_text('Next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-5233aeaef127>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-5233aeaef127>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <div class=”container” id=”box”></div>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
